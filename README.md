# Gradient Descent Tutorial

**A comprehensive guide to understanding and implementing Gradient Descent and its variants using Python.**

---

## Overview

This tutorial explores the fundamentals of Gradient Descent, a core optimization algorithm in machine learning. It covers the following:
- **Core Concepts**: Cost functions, gradients, and the role of learning rates.
- **Variants of Gradient Descent**: Batch, Stochastic, Mini-Batch, and Momentum-Based Gradient Descent.
- **Applications**: Machine learning tasks, including regression, classification, and neural network training.
- **Hands-On Code**: Python implementations and visualizations to demonstrate the concepts.

---

## Repository Contents

1. **Code Files**:
   - `gradient_descent_visualization.py`: Visualizes cost function convergence and parameter updates.
   - `linear_regression_gradient_descent.py`: Demonstrates Gradient Descent for linear regression.
   - `gradient_descent_variants.py`: Implements and compares Batch, Stochastic, Mini-Batch, and Momentum Gradient Descent.

2. **Interactive Google Colab Notebooks**:
   - [Gradient Descent Visualization](https://colab.research.google.com/drive/1MWNfVJAM3DbVrlMyxkn1dH6TjQXsdJRH?usp=sharing)  
   - [Linear Regression with Gradient Descent](https://colab.research.google.com/drive/1b2njFNUBrRHhy8_98pgbTDnNEpBZasA2?usp=sharing)  
   - [Gradient Descent Variants](https://colab.research.google.com/drive/1Kq526DTzgkLC37fDIHQadjRloVrWHBvf?usp=sharing)

3. **Figures and Visualizations**:
   - Pre-generated plots of cost function convergence and parameter updates.

---

## Getting Started

### Prerequisites
Ensure the following libraries are installed:
```bash
pip install numpy matplotlib
```
---
## **Running the Code Locally**

To run the Python scripts locally, follow these steps:

1. **Clone the repository**:
   ```bash
   git clone https://github.com/yourusername/gradient-descent-tutorial.git
   cd gradient-descent-tutorial
   python code/gradient_descent_visualization.py
